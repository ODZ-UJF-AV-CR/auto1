{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a new frame:  0\n",
      "Read a new frame:  100\n",
      "Read a new frame:  200\n",
      "Read a new frame:  300\n",
      "Read a new frame:  400\n",
      "Read a new frame:  500\n",
      "Read a new frame:  600\n",
      "Read a new frame:  700\n",
      "Read a new frame:  800\n",
      "Read a new frame:  900\n",
      "Read a new frame:  1000\n",
      "Read a new frame:  1100\n",
      "Read a new frame:  1200\n",
      "Read a new frame:  1300\n",
      "Read a new frame:  1400\n",
      "Read a new frame:  1500\n",
      "Read a new frame:  1600\n",
      "Read a new frame:  1700\n",
      "Read a new frame:  1800\n",
      "Read a new frame:  1900\n",
      "Read a new frame:  2000\n",
      "Read a new frame:  2100\n",
      "Read a new frame:  2200\n",
      "Read a new frame:  2300\n",
      "Read a new frame:  2400\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) /build/source/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m success:\n\u001b[1;32m     24\u001b[0m     success,frame \u001b[38;5;241m=\u001b[39m vidcap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 25\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m#th, dst = cv2.threshold(image, brightest-200, None, cv2.THRESH_TOZERO);\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m#th = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39madaptiveThreshold(image,\u001b[38;5;241m255\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mADAPTIVE_THRESH_GAUSSIAN_C,cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) /build/source/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "import datetime \n",
    "\n",
    "directory = \"/storage/experiments/2021/0725_bourka_ratmirov\"\n",
    "\n",
    "f = directory + \"/video/output/1627302288.9546976.mp4\"\n",
    "vidcap = cv2.VideoCapture(f)\n",
    "success,frame = vidcap.read()\n",
    "\n",
    "time_string = \"25/07/21 18:24:47.956\"\n",
    "format_string = \"%d/%m/%y %H:%M:%S.%f\"\n",
    "t = datetime.datetime.strptime(time_string, format_string)\n",
    "t += datetime.timedelta(microseconds=620)\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "while success:\n",
    "    success,frame = vidcap.read()\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #th, dst = cv2.threshold(image, brightest-200, None, cv2.THRESH_TOZERO);\n",
    "    #th = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    image = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,3,5)\n",
    "\n",
    "    if (count2 == 0):\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        color = (0, 255, 0) # red\n",
    "        fontsize = 1\n",
    "        text = \"test\"\n",
    "        position = (10, 300)\n",
    "        cv2.putText(image, 'frame: ' + str(count), position, font, color=color, thickness = 2, fontScale=2)\n",
    "        position = (10, 1000)\n",
    "        cv2.putText(image, 'time: ' + str(t), position, font, color=color, thickness = 2, fontScale=1)\n",
    "        print('Read a new frame: ', count)\n",
    "        cv2.imwrite(directory + '/video/output/img/%d.jpg' % count, image)     # save frame as JPEG file\n",
    "    t+=datetime.timedelta(microseconds=620) \n",
    "    count += 1\n",
    "    count2 += 1\n",
    "    if (count2==100):\n",
    "        count2 = 0\n",
    "vidcap.release()\n",
    "        \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "import datetime \n",
    "\n",
    "directory = \"/storage/experiments/2021/video_lightning_highlights\"\n",
    "\n",
    "f = directory + \"/video/2021-08-15-20-07-35.912167-lightning.mp4\"\n",
    "f = directory + \"/video/1627302745.846055.mp4\"\n",
    "f = directory + \"/video/1627302288.9546976.mp4\"\n",
    "vidcap = cv2.VideoCapture(f)\n",
    "success,image = vidcap.read()\n",
    "\n",
    "time_string = \"25/07/21 18:24:47.956\"\n",
    "format_string = \"%d/%m/%y %H:%M:%S.%f\"\n",
    "t = datetime.datetime.strptime(time_string, format_string)\n",
    "t += datetime.timedelta(microseconds=620)\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "success,frame = vidcap.read()\n",
    "image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#stacked = np.float32(image)\n",
    "stacked = image #.astype(np.float32)\n",
    "while True:\n",
    "    success,frame = vidcap.read()\n",
    "    if (success):\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh = cv2.threshold(image,80,255,cv2.THRESH_TOZERO)\n",
    "        #image = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,3,5)\n",
    "        #stacked = cv2.add(stacked,thresh1)\n",
    "        nonzero =  cv2.countNonZero(thresh)\n",
    "        if (nonzero<3000):\n",
    "            stacked = cv2.add(stacked,thresh)\n",
    "            #stacked += (thresh-70)*2\n",
    "        #stacked = cv2.addWeighted(stacked,0.9,image,0.9,0.0)\n",
    "\n",
    "        #stacked = cv2.addWeighted(stacked,1,image,1,0.5)\n",
    "        #stacked = cv2.phaseCorrelate(image,stacked)\n",
    "        #stacked = (stacked+image*.1);\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.imwrite(directory + '/video/output/img/stacked.jpg', stacked)     # save frame as JPEG file\n",
    "\n",
    "vidcap.release()\n",
    "        \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "import datetime \n",
    "\n",
    "directory = \"/storage/experiments/2021/video_lightning_highlights\"\n",
    "\n",
    "f = directory + \"/video/2021-08-15-20-07-35.912167-lightning.mp4\"\n",
    "f = directory + \"/video/1627302745.846055.mp4\"\n",
    "f = directory + \"/video/1627302288.9546976.mp4\"\n",
    "vidcap = cv2.VideoCapture(f)\n",
    "\n",
    "stackedR = np.zeros(stacked.shape[:2], dtype=\"uint8\")\n",
    "stackedG = np.zeros(stacked.shape[:2], dtype=\"uint8\")\n",
    "stackedB = np.zeros(stacked.shape[:2], dtype=\"uint8\")\n",
    "while True:\n",
    "    success,frame = vidcap.read()\n",
    "    if (success):\n",
    "        (B, G, R) = cv2.split(frame)\n",
    "        threshR = R\n",
    "        threshG = G\n",
    "        threshB = B\n",
    "        #ret,threshR = cv2.threshold(R,80,255,cv2.THRESH_TOZERO)\n",
    "        #ret,threshG = cv2.threshold(G,80,255,cv2.THRESH_TOZERO)\n",
    "        #ret,threshB = cv2.threshold(B,80,255,cv2.THRESH_TOZERO)\n",
    "        nonzero =  cv2.countNonZero(threshR)\n",
    "        if (nonzero<30000):\n",
    "            stackedR += threshR\n",
    "            stackedG += threshG\n",
    "            stackedB += threshB\n",
    "            #stackedR = cv2.add(stackedR,threshR)\n",
    "            #stackedG = cv2.add(stackedG,threshG)\n",
    "            #stackedB = cv2.add(stackedB,threshB)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "zeros = np.zeros(stacked.shape[:2], dtype=\"uint8\")\n",
    "stacked =  cv2.merge([zeros, zeros, stackedR])\n",
    "#stacked = cv2.merge([stackedB,stackedG,stackedR])\n",
    "cv2.imwrite(directory + '/video/output/img/stacked.jpg', stackedR)     # save frame as JPEG file\n",
    "\n",
    "vidcap.release()\n",
    "        \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "import datetime \n",
    "\n",
    "directory = \"/storage/experiments/2021/video_lightning_highlights\"\n",
    "\n",
    "f = directory + \"/video/2021-08-15-20-07-35.912167-lightning.mp4\"\n",
    "f = directory + \"/video/1627302745.846055.mp4\"\n",
    "f = directory + \"/video/1627302288.9546976.mp4\"\n",
    "vidcap = cv2.VideoCapture(f)\n",
    "success,image = vidcap.read()\n",
    "\n",
    "time_string = \"25/07/21 18:24:47.956\"\n",
    "format_string = \"%d/%m/%y %H:%M:%S.%f\"\n",
    "t = datetime.datetime.strptime(time_string, format_string)\n",
    "t += datetime.timedelta(microseconds=620)\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "success,frame = vidcap.read()\n",
    "image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#stacked = np.float32(image)\n",
    "stacked = image #.astype(np.float32)\n",
    "while True:\n",
    "    success,frame = vidcap.read()\n",
    "    if (success):\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh = cv2.threshold(image,80,255,cv2.THRESH_TOZERO)\n",
    "        #image = cv2.adaptiveThreshold(image,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,3,5)\n",
    "        #stacked = cv2.add(stacked,thresh1)\n",
    "        nonzero =  cv2.countNonZero(thresh)\n",
    "        if (nonzero<3000):\n",
    "            #stacked = cv2.add(stacked,thresh)\n",
    "            stacked += thresh\n",
    "            #stacked = cv2.addWeighted(stacked,0.9,image,0.9,0.0)\n",
    "\n",
    "        #stacked = cv2.addWeighted(stacked,1,image,1,0.5)\n",
    "        #stacked = cv2.phaseCorrelate(image,stacked)\n",
    "        #stacked = (stacked+image*.1);\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#colorimg = cv2.cvtColor(stacked, cv2.COLOR_GRAY2BGR) \n",
    "colorimg = cv2.applyColorMap(stacked, cv2.COLORMAP_JET)\n",
    "\n",
    "cv2.imwrite(directory + '/video/output/img/stacked.jpg', colorimg)     # save frame as JPEG file\n",
    "\n",
    "vidcap.release()\n",
    "        \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pandas as pd \n",
    "import datetime \n",
    "\n",
    "#directory = \"/storage/experiments/2021/0725_bourka_ratmirov\"\n",
    "directory = \"/storage/experiments/2021/video_lightning_highlights\"\n",
    "\n",
    "f = directory + \"/video/2021-08-15-20-07-35.912167-lightning.mp4\"\n",
    "vidcap = cv2.VideoCapture(f)\n",
    "success,image = vidcap.read()\n",
    "\n",
    "time_string = \"25/07/21 18:24:47.956\"\n",
    "format_string = \"%d/%m/%y %H:%M:%S.%f\"\n",
    "t = datetime.datetime.strptime(time_string, format_string)\n",
    "t += datetime.timedelta(microseconds=620)\n",
    "\n",
    "count = 0\n",
    "count2 = 0\n",
    "success,image1 = vidcap.read()\n",
    "stacked = cv2.bitwise_xor(image1,image1)\n",
    "#cv2.imwrite(directory + '/video/output/img/stacked1.jpg', stacked)     # save frame as JPEG file\n",
    "\n",
    "while True:\n",
    "    success,image = vidcap.read()\n",
    "    count += 1\n",
    "    if (count > 0): \n",
    "        break;\n",
    "    \n",
    "#stacked = np.float32(image)\n",
    "#stacked = image\n",
    "while True:\n",
    "    success,image = vidcap.read()\n",
    "    #success,image2 = vidcap.read()\n",
    "    if (success):\n",
    "        #image = cv2.bitwise_xor(image1,image2)\n",
    "        #stacked = cv2.add(image,stacked)\n",
    "        rave = image.ravel()\n",
    "        illuminance = rave.sum()\n",
    "        brightest = rave.max()\n",
    "\n",
    "        if (illuminance < 6e6 ): #6e6\n",
    "            th, dst = cv2.threshold(image, brightest-200, None, cv2.THRESH_TOZERO);\n",
    "            #stacked = cv2.addWeighted(dst, 1.0, stacked, 1.0, 0.0)\n",
    "            stacked = cv2.add(dst, stacked)\n",
    "        #stacked = cv2.normalize(stacked, None, alpha=0,beta=275, norm_type=cv2.NORM_MINMAX)\n",
    "        #stacked = cv2.normalize(stacked, None, alpha=1,beta=0, norm_type=cv2.NORM_L2)\n",
    "        #stacked = cv2.addWeighted(stacked,1,image,1,0.5)\n",
    "        #stacked = cv2.phaseCorrelate(image,stacked)\n",
    "        #stacked = (stacked+image*.1);\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.imwrite(directory + '/video/output/img/stacked.jpg', stacked)     # save frame as JPEG file\n",
    "\n",
    "vidcap.release()\n",
    "        \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"/storage/experiments/2021/video_lightning_highlights\"\n",
    "\n",
    "file = 'untitled.mp4'\n",
    "\n",
    "# Logarithmic transformation\n",
    "def log(c, img):\n",
    "    output = c * np.log(1.0 + img)\n",
    "    output = np.uint8(output)\n",
    "    #output = c * np.log(1.0 + img)\n",
    "    #output = np.uint8(output + 0.5)\n",
    "    return output\n",
    "\n",
    "try:\n",
    "    os.mkdir(directory + '/video/output')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "f = directory + \"/video/\" + file \n",
    "    \n",
    "b = np.zeros(30000)\n",
    "\n",
    "vcap = cv2.VideoCapture(f)\n",
    "\n",
    "if vcap.isOpened(): \n",
    "    # get vcap property \n",
    "    width  = vcap.get(3)  # float `width`\n",
    "    height = vcap.get(4)  # float `height`\n",
    "\n",
    "print(width, ' x ', height)\n",
    "vcap.release()\n",
    "\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "out = cv2.VideoWriter(directory + '/video/output/' + file , fourcc, 20.0, (round(width),round(height)))\n",
    "\n",
    "cap = cv2.VideoCapture(f)\n",
    "\n",
    "\n",
    "lut = np.zeros((256, 1, 3), dtype=np.uint8)\n",
    "\n",
    "#Red\n",
    "lut[:, 0, 0] = [255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,253,251,249,247,245,242,241,238,237,235,233,231,229,227,225,223,221,219,217,215,213,211,209,207,205,203,201,199,197,195,193,191,189,187,185,183,181,179,177,175,173,171,169,167,165,163,161,159,157,155,153,151,149,147,145,143,141,138,136,134,132,131,129,126,125,122,121,118,116,115,113,111,109,107,105,102,100,98,97,94,93,91,89,87,84,83,81,79,77,75,73,70,68,66,64,63,61,59,57,54,52,51,49,47,44,42,40,39,37,34,33,31,29,27,25,22,20,18,17,14,13,11,9,6,4,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "#Green\n",
    "lut[:, 0, 1] = [ 255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,254,252,250,248,246,244,242,240,238,236,234,232,230,228,226,224,222,220,218,216,214,212,210,208,206,204,202,200,198,196,194,192,190,188,186,184,182,180,178,176,174,171,169,167,165,163,161,159,157,155,153,151,149,147,145,143,141,139,137,135,133,131,129,127,125,123,121,119,117,115,113,111,109,107,105,103,101,99,97,95,93,91,89,87,85,83,82,80,78,76,74,72,70,68,66,64,62,60,58,56,54,52,50,48,46,44,42,40,38,36,34,32,30,28,26,24,22,20,18,16,14,12,10,8,6,4,2,0 ]\n",
    "\n",
    "#Blue\n",
    "lut[:, 0, 2] = [195,194,193,191,190,189,188,187,186,185,184,183,182,181,179,178,177,176,175,174,173,172,171,170,169,167,166,165,164,163,162,161,160,159,158,157,155,154,153,152,151,150,149,148,147,146,145,143,142,141,140,139,138,137,136,135,134,133,131,130,129,128,127,126,125,125,125,125,125,125,125,125,125,125,125,125,125,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126]\n",
    "\n",
    "def get_mpl_colormap(cmap_name):\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "\n",
    "    # Initialize the matplotlib color map\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap)\n",
    "\n",
    "    # Obtain linear color range\n",
    "    color_range = sm.to_rgba(np.linspace(0, 1, 256), bytes=True)[:,2::-1]\n",
    "\n",
    "    return color_range.reshape(256, 1, 3)\n",
    "\n",
    "\n",
    "success,image1 = cap.read()\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not(ret):\n",
    "        break\n",
    "\n",
    "    #frame_log = log(255,frame)\n",
    "    \n",
    "    #rave = frame[10:800, 100:800].ravel()\n",
    "    #brightest = rave.max()\n",
    "    #print(brightest)\n",
    "    \n",
    "    frame_color = cv2.applyColorMap(frame*2, cv2.COLORMAP_PLASMA)\n",
    "    #frame_color = cv2.applyColorMap(frame, get_mpl_colormap('plasma'))\n",
    "    #frame_color = cv2.LUT(frame, lut)\n",
    "\n",
    "    count = count + 1\n",
    "    out.write(frame_color)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "print(f)\n",
    "        \n",
    "print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "ipython_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
